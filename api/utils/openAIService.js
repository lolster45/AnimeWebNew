import dotenv from 'dotenv';
dotenv.config();

//Hugging face client...
import { HfInference } from '@huggingface/inference';
const client = new HfInference(process.env.HUGGINGFACE_API_KEY);


const getAiResponse = async (prompt) => {
  try {
    // const response = await fetch(HUGGINGFACE_BASE_URL, {

    //   method: 'POST',
    //   headers: {
    //     'Authorization': `Bearer ${HUGGINGFACE_API_KEY}`,
    //     'Content-Type': 'application/json',
    //   },
    //   body: JSON.stringify({
    //     inputs: prompt,
    //   }),
    // });

    const chatCompletion = await client.chatCompletion({
      model: "mistralai/Mistral-7B-Instruct-v0.3",
      messages: [
        {
          role: "user",
          content: prompt, // Dynamically using the passed prompt instead of a hardcoded one.
        }
      ],
      provider: "hf-inference",
      max_tokens: 150,
    });

    // Extract the generated response text.
    const generatedText = chatCompletion.choices[0]?.message?.content;

    if (!generatedText) {
      throw new Error('No response generated by the model.');
    }

    return generatedText; // Return the generated text.
  } 
  catch (error) {
    console.error("Error communicating with Hugging Face API:", error);
    throw error;
  }
};

export default getAiResponse;